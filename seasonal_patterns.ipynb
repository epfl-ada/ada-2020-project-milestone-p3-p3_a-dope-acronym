{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pygeohash as pgh\n",
    "import matplotlib.pyplot as plt\n",
    "import reverse_geocoder as rg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Seasonal Patterns in User Movement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The datasets have no headers, so we have to name them for clarity\n",
    "checkin_header = ['user', 'checkin_time', 'latitude', 'longitude', 'location_id']\n",
    "edges_header = ['user1', 'user2']\n",
    "\n",
    "# Load the data by specifying the correct compression algorithm, separator and column names\n",
    "checkin_brightkite_orig = pd.read_csv('data/loc-brightkite_totalCheckins.txt.gz', compression = 'gzip', sep = '\\t', names = checkin_header)\n",
    "edges_brightkite_orig = pd.read_csv('data/loc-brightkite_edges.txt.gz', compression = 'gzip', sep = '\\t', names = edges_header)\n",
    "checkin_gowalla_orig = pd.read_csv('data/loc-gowalla_totalCheckins.txt.gz', compression = 'gzip', sep = '\\t', names = checkin_header)\n",
    "edges_gowalla_orig = pd.read_csv('data/loc-gowalla_edges.txt.gz', compression = 'gzip', sep = '\\t', names = edges_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the dataframe in order not to have to reload the original one in case of a mistake\n",
    "checkin_gowalla = checkin_gowalla_orig.copy()\n",
    "to_drop = []\n",
    "# Select indexes to drop depending on conditions mentionned above \n",
    "to_drop.append(checkin_gowalla_orig[(checkin_gowalla_orig['latitude'] < -90.0) | \n",
    "                               (checkin_gowalla_orig['latitude'] > 90.0)].index)\n",
    "to_drop.append(checkin_gowalla_orig[(checkin_gowalla_orig['longitude'] < -180.0) | \n",
    "                               (checkin_gowalla_orig['longitude'] > 180.0)].index)\n",
    "to_drop.append(checkin_gowalla_orig[(checkin_gowalla_orig['latitude'] == 0) & \n",
    "                               (checkin_gowalla_orig['longitude'] == 0)].index)\n",
    "# Drop the invalid rows in place from the copied dataframe\n",
    "for item in to_drop:\n",
    "    checkin_gowalla.drop(item, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the process on the other data set\n",
    "checkin_brightkite = checkin_brightkite_orig.copy()\n",
    "to_drop = []\n",
    "to_drop.append(checkin_brightkite_orig[(checkin_brightkite_orig['latitude'] < -90.0) | \n",
    "                                  (checkin_brightkite_orig['latitude'] > 90.0)].index)\n",
    "to_drop.append(checkin_brightkite_orig[(checkin_brightkite_orig['longitude'] < -180.0) | \n",
    "                                  (checkin_brightkite_orig['longitude'] > 180.0)].index)\n",
    "to_drop.append(checkin_brightkite_orig[(checkin_brightkite_orig['latitude'] == 0) & \n",
    "                                  (checkin_brightkite_orig['longitude'] == 0)].index)\n",
    "for item in to_drop:\n",
    "    checkin_brightkite.drop(item, inplace = True)\n",
    "# Drop rows with NaN values\n",
    "checkin_brightkite.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding country information to check-ins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinates_to_country(df):\n",
    "    \"\"\"\n",
    "    Maps the coordinates of a dataframe to the country\n",
    "    code using reverse geocoding\n",
    "    \"\"\"\n",
    "    coordinates_tuples = list(df.apply(lambda x: (x['latitude'], x['longitude']), axis = 1))\n",
    "    geocodes = rg.search(coordinates_tuples)\n",
    "    return [gc['cc'] for gc in geocodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading formatted geocoded file...\n"
     ]
    }
   ],
   "source": [
    "# Append country codes to each check-in for both datasets\n",
    "checkin_brightkite['cc'] = coordinates_to_country(checkin_brightkite)\n",
    "checkin_gowalla['cc'] = coordinates_to_country(checkin_gowalla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining the location of user homes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the geohash for each checkin entry: that will determine the cell in which each checkin belongs\n",
    "checkin_brightkite['geohash'] = checkin_brightkite.apply(lambda row: pgh.encode(row.latitude, row.longitude, precision=4) , axis = 1)\n",
    "checkin_gowalla['geohash'] = checkin_gowalla.apply(lambda row: pgh.encode(row.latitude, row.longitude, precision=4) , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brightkite_users = set(checkin_brightkite.user) # All the users that made at least 1 checkin\n",
    "brightkite_per_user = checkin_brightkite.groupby(['user']) # Group the checkins by user\n",
    "\n",
    "# Group the checkins by user and by geohash to be able to retrieve the most common geohash per user\n",
    "brightkite_checkin_cells = checkin_brightkite.groupby(['user', 'geohash']).size() \n",
    "\n",
    "brightkite_homes = {} # To associate each user ID to its inferred home location\n",
    "for user in brightkite_users:\n",
    "    geohash = brightkite_checkin_cells[user].idxmax() # Get the most common geohash for the user\n",
    "    group = brightkite_per_user.get_group(user) # Retrieve all the user's checkins\n",
    "    \n",
    "    # Keep all checkins that happened in the most common geohash and compute average position\n",
    "    brightkite_homes[user] = group[group['geohash'] == geohash][['latitude', 'longitude']].mean()\n",
    "\n",
    "# Create a dataframe containing the home location for each user \n",
    "brightkite_homes = pd.DataFrame.from_dict(brightkite_homes, orient = 'index')\n",
    "\n",
    "# Add country code information for home locations \n",
    "brightkite_homes['cc'] = coordinates_to_country(brightkite_homes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gowalla_users = set(checkin_gowalla.user) \n",
    "gowalla_per_user = checkin_gowalla.groupby(['user']) \n",
    "\n",
    "gowalla_checkin_cells = checkin_gowalla.groupby(['user', 'geohash']).size()\n",
    "\n",
    "gowalla_homes = {} \n",
    "for user in gowalla_users:\n",
    "    geohash = gowalla_checkin_cells[user].idxmax() \n",
    "    group = gowalla_per_user.get_group(user) \n",
    "    gowalla_homes[user] = group[group['geohash'] == geohash][['latitude', 'longitude']].mean()\n",
    "\n",
    "gowalla_homes = pd.DataFrame.from_dict(gowalla_homes, orient = 'index')\n",
    "gowalla_homes['cc'] = coordinates_to_country(gowalla_homes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(checkin_brightkite, open('pickles/checkin_brightkite', 'wb'))\n",
    "pickle.dump(checkin_gowalla, open('pickles/checkin_gowalla', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To reload for later\n",
    "# pickle.load(open('pickles/checkin_brightkite', 'rb'))\n",
    "# pickle.load(open('pickles/checkin_gowalla', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
