{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pygeohash as pgh\n",
    "import matplotlib.pyplot as plt\n",
    "import reverse_geocoder as rg\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import math\n",
    "\n",
    "# import geopy.distance\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm_notebook\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(nb_workers=8, progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Seasonal Patterns in User Movement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is more to human movement than periodic patterns and social-based movement. While the paper accurately predicts human movement throughout the week, we propose a more all-encompassing analysis that paints a broader picture, exploring monthly and seasonal movement. To do so, we will use the original check-in and friendship datasets from Gowalla and Brightkite and separate them into subsets representing a narrower time of the year. We want to see what mobility patterns are exhibited in different countries and throughout different times of the year: users can go on vacation, travel abroad, and change homes. This would allow us to understand the travelling patterns of users around the world (i.e. who is more likely to travel and where) as well as the distribution of check-ins and their density. We want to produce visualizations showcasing these patterns on a world map. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our starting point is the first replication of the Friendship and Mobility paper. We re-use the data-loading and data cleaning part, as well as the technique to determine home locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The datasets have no headers, so we have to name them for clarity\n",
    "checkin_header = ['user', 'checkin_time', 'latitude', 'longitude', 'location_id']\n",
    "edges_header = ['user1', 'user2']\n",
    "\n",
    "# Load the data by specifying the correct compression algorithm, separator and column names\n",
    "checkin_brightkite_orig = pd.read_csv('data/loc-brightkite_totalCheckins.txt.gz', compression = 'gzip', sep = '\\t', names = checkin_header)\n",
    "edges_brightkite_orig = pd.read_csv('data/loc-brightkite_edges.txt.gz', compression = 'gzip', sep = '\\t', names = edges_header)\n",
    "checkin_gowalla_orig = pd.read_csv('data/loc-gowalla_totalCheckins.txt.gz', compression = 'gzip', sep = '\\t', names = checkin_header)\n",
    "edges_gowalla_orig = pd.read_csv('data/loc-gowalla_edges.txt.gz', compression = 'gzip', sep = '\\t', names = edges_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the latitude and longitude values are not in the valid range of [-90, 90] and [-180, 180] respectively. Moreover, the location having (lat, long) = (0,0) is not a valid one . In both datasets, we remove rows in which either of the location attributes are not valid. We also remove the rows of the Brightkite dataset that have NaN values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(checkins):\n",
    "    \"\"\" Rids the check-in data of invalid coordinates \"\"\"\n",
    "    to_drop = []\n",
    "    # Select indexes to drop depending on conditions mentionned above \n",
    "    to_drop.append(checkins[(checkins['latitude'] < -90.0) | \n",
    "                                   (checkins['latitude'] > 90.0)].index)\n",
    "    to_drop.append(checkins[(checkins['longitude'] < -180.0) | \n",
    "                                   (checkins['longitude'] > 180.0)].index)\n",
    "    to_drop.append(checkins[(checkins['latitude'] == 0) & \n",
    "                                   (checkins['longitude'] == 0)].index)\n",
    "    \n",
    "    for item in to_drop:\n",
    "        checkins.drop(item, inplace = True)\n",
    "    checkins.dropna(inplace = True)\n",
    "    \n",
    "    return checkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass copy of DataFrama in order not to have to reload the original one in case of a mistake\n",
    "checkin_brightkite = clean(checkin_brightkite_orig.copy())\n",
    "checkin_gowalla    = clean(checkin_gowalla_orig.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding country information to check-ins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each check-in, we append the country code corresponding to the country the check-in was made in. This is done using a reverse geohashing library [`reverse_geocoder`](https://github.com/thampiman/reverse-geocoder) that maps coordinates (latitutde, longitude) to information about a specific place (e.g. city, country, country code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coordinates(row):\n",
    "    return (row['latitude'], row['longitude'])\n",
    "\n",
    "def coordinates_to_country(df):\n",
    "    \"\"\"\n",
    "        Maps the coordinates of a dataframe to the country\n",
    "        code using reverse geocoding\n",
    "    \"\"\"\n",
    "    coordinates_tuples = list(df.parallel_apply(extract_coordinates, axis = 1))\n",
    "    geocodes = rg.search(coordinates_tuples)\n",
    "    return [gc['cc'] for gc in geocodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d72cf0e36f884adf82ae3de67818d339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=561380), Label(value='0 / 561380')â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-15:\n",
      "Process ForkPoolWorker-14:\n",
      "Process ForkPoolWorker-11:\n",
      "Process ForkPoolWorker-13:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-10:\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-12:\n",
      "Process ForkPoolWorker-16:\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-17:\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/queues.py\", line 356, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/karim/anaconda3/envs/ada/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-dce12d68b5ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# # Append country codes to each check-in for both datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcheckin_brightkite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cc'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoordinates_to_country\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckin_brightkite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcheckin_gowalla\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cc'\u001b[0m\u001b[0;34m]\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mcoordinates_to_country\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckin_gowalla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcheckin_brightkite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-8f3c36a74f7f>\u001b[0m in \u001b[0;36mcoordinates_to_country\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0musing\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0mgeocoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \"\"\"\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mcoordinates_tuples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_coordinates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mgeocodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoordinates_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cc'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgeocodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/site-packages/pandarallel/pandarallel.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m(data, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             results = get_workers_result(\n\u001b[0m\u001b[1;32m    454\u001b[0m                 \u001b[0muse_memory_fs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                 \u001b[0mnb_workers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/site-packages/pandarallel/pandarallel.py\u001b[0m in \u001b[0;36mget_workers_result\u001b[0;34m(use_memory_fs, nb_workers, show_progress_bar, nb_columns, queue, chunk_lengths, input_files, output_files, map_result)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinished_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mmessage_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mINPUT_FILE_READ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/multiprocessing/managers.py\u001b[0m in \u001b[0;36m_callmethod\u001b[0;34m(self, methodname, args, kwds)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethodname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         \u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'#RETURN'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # Append country codes to each check-in for both datasets\n",
    "checkin_brightkite['cc'] = coordinates_to_country(checkin_brightkite)\n",
    "checkin_gowalla['cc']    = coordinates_to_country(checkin_gowalla)\n",
    "\n",
    "checkin_brightkite.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining the location of user homes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the geohash is used to determine the home location for every user. Since this is similar to what was done in the replication, we will not go into detail about the implementation and justification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geohash_encode(row, precision = 4):\n",
    "    \"\"\"\n",
    "        Computes and returns the geohash with \n",
    "        precision 4 for a given row \n",
    "    \"\"\"\n",
    "    return pgh.encode(*extract_coordinates(row), precision=precision)\n",
    "\n",
    "def find_home(checkins, user_id):\n",
    "    \"\"\"\n",
    "        Given a user id, finds the most common world cell and \n",
    "        computes average location to estimate home location\n",
    "    \"\"\"\n",
    "    # Retrieve all the user's check-ins\n",
    "    group = checkins[checkins['user']  == user_id]\n",
    "    # Get the most common geohash for the user\n",
    "    geohash = group.groupby('geohash').size().idxmax()\n",
    "    \n",
    "    # Keep all checkins that happened in the most common geohash and compute average position\n",
    "    return group[group['geohash'] == geohash][['latitude', 'longitude']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the geohash for each check-in entry: that will determine the cell in which each check-in belongs\n",
    "checkin_brightkite['geohash'] = checkin_brightkite.parallel_apply(geohash_encode, axis = 1)\n",
    "checkin_gowalla['geohash']    = checkin_gowalla.parallel_apply(geohash_encode, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the users that made at least 1 check-in\n",
    "brightkite_users = set(checkin_brightkite.user)\n",
    "gowalla_users = set(checkin_gowalla.user)\n",
    "\n",
    "# Create empty DataFrame with user ids and apply function to all users\n",
    "brightkite_homes = pd.DataFrame(index = brightkite_users).index.to_series().parallel_apply(lambda user_id: find_home(checkin_brightkite, user_id)) \n",
    "gowalla_homes = pd.DataFrame(index = gowalla_users).index.to_series().parallel_apply(lambda user_id: find_home(checkin_gpwalla, user_id)) \n",
    "\n",
    "# Add the country codes to the homes\n",
    "brightkite_homes['cc'] = coordinates_to_country(brightkite_homes)\n",
    "gowalla_homes['cc'] = coordinates_to_country(gowalla_homes)\n",
    "\n",
    "brightkite_homes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding temporal information to the check-in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to separate check-ins temporally, we add to each check-in, the month and season it was made in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_datetime(row):\n",
    "    \"\"\" Returns the string found in the row to the correctly formatted datetime object \"\"\"\n",
    "    return datetime.strptime(row['checkin_time'], '%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "def get_month(row):\n",
    "    \"\"\" Extracts the month from the given row. \"\"\"\n",
    "    return to_datetime(row).month\n",
    "\n",
    "def get_day(row):\n",
    "    \"\"\" Extracts the day from the given row. \"\"\"\n",
    "    return to_datetime(row).weekday() # Monday is 0, Sunday is 6\n",
    "\n",
    "def hour_of_week(row):\n",
    "    \"\"\" Extracts the hour of the week. A week has 168 hours. \"\"\"\n",
    "    return to_datetime(row).weekday()*24 + to_datetime(row).hour\n",
    "\n",
    "def get_season(row):\n",
    "    \"\"\" \n",
    "        Returns the season from a certain row\n",
    "        Adapted from https://stackoverflow.com/a/28688724 \n",
    "    \"\"\"\n",
    "    date_time = to_datetime(row)\n",
    "    date_time = date_time.replace(year=Y, hour=0, minute=0, second=0)\n",
    "    \n",
    "    # Define the datetime intervals according to every season\n",
    "    Y = 2000 # Leap year to allow input X-02-29, which allows for leap days\n",
    "    seasons = [('winter', (datetime(Y,  1,  1),  datetime(Y,  3, 20))),\n",
    "               ('spring', (datetime(Y,  3, 21),  datetime(Y,  6, 20))),\n",
    "               ('summer', (datetime(Y,  6, 21),  datetime(Y,  9, 22))),\n",
    "               ('autumn', (datetime(Y,  9, 23),  datetime(Y, 12, 20))),\n",
    "               ('winter', (datetime(Y, 12, 21),  datetime(Y, 12, 31)))]\n",
    "    \n",
    "    return next(season for season, (start, end) in seasons_periods if start <= date_time <= end)\n",
    "\n",
    "seasons = ['Winter', 'Spring', 'Summer', 'Autumn']\n",
    "months = {1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June',\\\n",
    "          7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the month associated with every check-in\n",
    "checkin_brightkite['month'] = checkin_brightkite.parallel_apply(get_month, axis=1)\n",
    "checkin_gowalla['month'] = checkin_gowalla.parallel_apply(get_month, axis=1)\n",
    "\n",
    "# Find the season associated with every check-in\n",
    "checkin_brightkite['season'] = checkin_brightkite.parallel_apply(get_season, axis=1)\n",
    "checkin_gowalla['season'] = checkin_gowalla.parallel_apply(get_season, axis=1)\n",
    "\n",
    "# Find the day of week associated with every check-in\n",
    "checkin_brightkite['day_of_week'] = checkin_brightkite.parallel_apply(day_of_week, axis=1)\n",
    "checkin_gowalla['day_of_week'] = checkin_gowalla.parallel_apply(day_of_week, axis=1)\n",
    "\n",
    "# Find the hour of week assoiated with every check-in (used for entropy) \n",
    "checkin_brightkite['hour_of_week'] = checkin_brightkite.parallel_apply(hour_of_week, axis=1)\n",
    "checkin_gowalla['hour_of_week'] = checkin_gowalla.parallel_apply(hour_of_week, axis=1)\n",
    "\n",
    "checkin_brightkite.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify travelers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now indentify users who travel. We define a traveler as a user who has made at least one check-in outside of his home country (determined by the country of its home location). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traveler_check(group):\n",
    "    \"\"\" A user is a traveler if he has ever checked in to more than one country \"\"\"\n",
    "    return True if len(set(group['cc'])) > 1 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find travellers in both datasets\n",
    "brightkite_homes['is_traveler'] = checkin_brightkite.groupby('user').parallel_apply(traveler_check)\n",
    "gowalla_homes['is_traveler'] = checkin_gowalla.groupby('user').parallel_apply(traveler_check)\n",
    "\n",
    "brightkite_homes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store homes in dictionary for faster access\n",
    "brightkite_homes = brightkite_homes.to_dict(orient = 'index')\n",
    "gowalla_homes = gowalla_homes.to_dict(orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_brightkite['is_abroad'] = checkin_brightkite.parallel_apply(lambda row: row['cc'] != brightkite_homes[row['user']]['cc'], axis = 1)\n",
    "checkin_gowalla['is_abroad'] = checkin_gowalla.parallel_apply(lambda row: row['cc'] != gowalla_homes[row['user']]['cc'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: add statistics on the data (i.e. where are travelers from)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When are users more likely to travel ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credits of the function implementation: https://stackoverflow.com/a/15737218\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "        Calculates the great circle distance (in km) between two points \n",
    "        on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # Convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    # Haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    # Radius of earth in kilometers is 6371\n",
    "    km = 6371* c\n",
    "    return km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_from_home(row, homes):\n",
    "    \"\"\" \n",
    "    calulate_home_distance_bk: calulates the distance between two lat/long coordinaes, which\n",
    "                               in this case are the homes of two friends using the coordinates\n",
    "                               in the bk_user_homes dataframe\n",
    "    arg row: a row from the dataframe containingn friend data\n",
    "    \"\"\"  \n",
    "    home_lat = homes[row['user']]['latitude']\n",
    "    home_long = homes[row['user']]['longitude']\n",
    "\n",
    "    return haversine(home_lat, home_long, row['latitude'], row['longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_brightkite['distance_from_home'] = checkin_brightkite.parallel_apply(lambda row: get_distance_from_home(row, brightkite_homes), axis=1)\n",
    "checkin_gowalla['distance_from_home'] = checkin_gowalla.parallel_apply(lambda row: get_distance_from_home(row, gowalla_homes), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dist = math.log10(checkin_brightkite.distance_from_home.max())\n",
    "checkin_brightkite[~checkin_brightkite['is_abroad']].distance_from_home.plot.kde(bw_method = 0.001, ind = np.logspace(0, max_dist, 50), loglog=True, \n",
    "                                                             ls = '', marker = 'o', fillstyle = 'none', color = 'blue')\n",
    "checkin_brightkite[checkin_brightkite['is_abroad']].distance_from_home.plot.kde(bw_method = 0.001, ind = np.logspace(0, max_dist, 50), loglog=True, \n",
    "                                                             ls = '', marker = 'o', fillstyle = 'none', color = 'lightblue')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.ylim(10e-8, 10e0)\n",
    "plt.legend(['Brightkite', 'Brightkite travelers', 'Gowalla', 'Gowalla travelers'])\n",
    "plt.xlabel('Check-in distance from home (km)')\n",
    "plt.show()\n",
    "# [TODO] This is kinda obvious on second thought: if user travels to another country, distance traveled is clearly gonna be > \n",
    "# Wouldn't it make more sense to plot the distance from home of check-ins made aborad, vs regular ones ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 4, figsize = (20, 10), sharex = True, sharey = True)\n",
    "axs = axs.ravel()\n",
    "\n",
    "max_dist = math.log10(checkin_brightkite.distance_from_home.max())\n",
    "\n",
    "for i in range(0, 12):\n",
    "    checkin_brightkite[(~checkin_brightkite['is_abroad']) & (checkin_brightkite['month'] == i+1)].distance_from_home.plot.kde(bw_method = 0.001, ind = np.logspace(0, max_dist, 30), loglog=True, \n",
    "                                                                 ls = '', marker = 'o', fillstyle = 'none', color = 'blue', ax = axs[i])\n",
    "    checkin_brightkite[(checkin_brightkite['is_abroad']) & (checkin_brightkite['month'] == i+1)].distance_from_home.plot.kde(bw_method = 0.001, ind = np.logspace(0, max_dist, 30), loglog=True, \n",
    "                                                                 ls = '', marker = 'o', fillstyle = 'none', color = 'lightblue', ax = axs[i])\n",
    "    \n",
    "#     checkin_gowalla[(~checkin_gowalla['is_traveler']) & (checkin_gowalla['month'] == i+1)].distance_from_home.plot.kde(bw_method = 0.001, ind = np.logspace(0, max_dist, 20), loglog=True, \n",
    "#                                                                  ls = '', marker = 'o', fillstyle = 'none', color = 'red', ax = axs[i])\n",
    "#     checkin_gowalla[(checkin_gowalla['is_traveler']) & (checkin_gowalla['month'] == i+1)].distance_from_home.plot.kde(bw_method = 0.001, ind = np.logspace(0, max_dist, 20), loglog=True, \n",
    "#                                                                  ls = '', marker = 'o', fillstyle = 'none', color = 'lightcoral', ax = axs[i])\n",
    "    axs[i].title.set_text(months[i+1])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.ylim(10e-8, 10e0)\n",
    "plt.legend(['Brightkite', 'Brightkite travelers', 'Gowalla', 'Gowalla travelers'])\n",
    "fig.text(0.5, 0, 'Check-in distance from home (km)', ha='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** since the question is \"when are users likely to travel\", we can check when do check-ins to another country occur (i.e. travel) and see if we can find a pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "checkin_brightkite[checkin_brightkite['is_abroad']].groupby('month')['user'].count().plot.bar()\n",
    "\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Check-in Count')\n",
    "plt.xticks(range(0, 12), labels=months.values(), rotation = 90)\n",
    "plt.suptitle('Distribution of check-ins made abroad, per month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing monthly and seasonal entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO (even though this does not mean users travels abroad, it still shows that their movement is more variable during these times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_brightkite['geohash_precision5'] = checkin_brightkite.parallel_apply(lambda row: geohash_encode(row, precision=5), axis = 1)\n",
    "checkin_gowalla['geohash_precision5'] = checkin_gowalla.parallel_apply(lambda row: geohash_encode(row, precision=5), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_entropies = []\n",
    "\n",
    "for i in range(12):\n",
    "    series = pd.Series(checkin_brightkite[checkin_brightkite['month'] == i+1].geohash_precision5)\n",
    "    monthly_entropies.append(entropy(series.value_counts()))\n",
    "\n",
    "plt.bar(x = list(range(1, 13)), height = monthly_entropies)\n",
    "\n",
    "plt.xticks(range(1, 13), labels=months.values(), rotation = 90)\n",
    "plt.ylim(8, 8.5)\n",
    "plt.xlabel('Months')\n",
    "plt.ylabel('Location Entropy')\n",
    "plt.suptitle('Entropy of check-in location over each month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_entropies = []\n",
    "\n",
    "for season in seasons:\n",
    "    series = pd.Series(checkin_brightkite[checkin_brightkite['season'] == season].geohash_precision5)\n",
    "    seasonal_entropies.append(entropy(series.value_counts()))\n",
    "\n",
    "plt.bar(x = seasons, height = seasonal_entropies)\n",
    "plt.ylim(8, 8.5)\n",
    "plt.xlabel('Seasons')\n",
    "plt.ylabel('Location Entropy')\n",
    "plt.suptitle('Entropy of check-in location over each season')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing weekly entropy on a monthly/seasonal basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_entropies = []\n",
    "for m in range(0, 12):\n",
    "    entropies = []\n",
    "    for i in range(168):\n",
    "        entropies.append(entropy(checkin_brightkite[(checkin_brightkite['hour_of_week'] == i) & (checkin_brightkite['month'] == m+1)]\\\n",
    "                                 .geohash_precision5.value_counts(), base = 2))\n",
    "    monthly_entropies.append(entropies)\n",
    "    \n",
    "fig, ax = plt.subplots(1, sharex = True, sharey = True, figsize = (20, 10))\n",
    "for i in range(0,12):\n",
    "    ax.plot(list(range(168)), monthly_entropies[i])\n",
    "    \n",
    "plt.legend(months.values())\n",
    "plt.xticks(ticks = [24*i + 12 for i in range(7)], labels = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\n",
    "plt.xlabel('Week day')\n",
    "plt.ylabel('Location Entropy')\n",
    "plt.suptitle('Weekly entropy aggregated over each month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_entropies = []\n",
    "for s in seasons:\n",
    "    entropies = []\n",
    "    for i in range(168):\n",
    "        entropies.append(entropy(checkin_brightkite[(checkin_brightkite['season'] == s) & (checkin_brightkite['hour_of_week'] == i)]\\\n",
    "                                 .geohash_precision5.value_counts(), base = 2))\n",
    "    seasonal_entropies.append(entropies)\n",
    "\n",
    "fig, ax = plt.subplots(1, sharex = True, sharey = True, figsize = (20, 10))\n",
    "for i in range(0,4):\n",
    "    ax.plot(list(range(168)), seasonal_entropies[i])\n",
    "for i in range(0,169, 24):\n",
    "    ax.axvline(i, color = 'grey', ls = '--')\n",
    "\n",
    "plt.legend(seasons)\n",
    "plt.xticks(ticks = [24*i + 12 for i in range(7)], labels = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\n",
    "plt.xlabel('Week day')\n",
    "plt.ylabel('Location Entropy')\n",
    "plt.suptitle('Weekly entropy aggregated over each season')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(checkin_brightkite, open('pickles/checkin_brightkite', 'wb'))\n",
    "# pickle.dump(checkin_gowalla, open('pickles/checkin_gowalla', 'wb'))\n",
    "\n",
    "# pickle.dump(brightkite_homes, open('pickles/brightkite_homes', 'wb'))\n",
    "# pickle.dump(gowalla_homes, open('pickles/gowalla_homes', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkin_brightkite = pickle.load(open('pickles/checkin_brightkite', 'rb'))\n",
    "# brightkite_homes = pickle.load(open('pickles/brightkite_homes', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada] *",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
